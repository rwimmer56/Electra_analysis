# ELECTRA

**ELECTRA** is a method for self-supervised language representation learning. It can be used to pre-train transformer networks using relatively little compute. ELECTRA models are trained to distinguish "real" input tokens vs "fake" input tokens generated by another neural network, similar to the discriminator of a [GAN](https://arxiv.org/pdf/1406.2661.pdf). At small scale, ELECTRA achieves strong results even when trained on a single GPU. At large scale, ELECTRA achieves state-of-the-art results on the [SQuAD 2.0](https://rajpurkar.github.io/SQuAD-explorer/) dataset.


## Used Models


| Model | Layers | Hidden Size | Params | GLUE score (test set) | Download |
| --- | --- | --- | --- | ---  | --- |
| ELECTRA-Large | 24 | 1024 | 335M |  85.2 | [link](https://storage.googleapis.com/electra-data/electra_large.zip) |

The model was trained on uncased English text. It corresponds to  ELECTRA-1.75M  in [ELECTRA paper](https://arxiv.org/abs/2003.10555).


## Requirements
* Python 3
* [TensorFlow](https://www.tensorflow.org/) 1.15 
* [NumPy](https://numpy.org/)
* [scikit-learn](https://scikit-learn.org/stable/) and [SciPy](https://www.scipy.org/) (for computing some evaluation metrics).






### Setup
Assuming you cloned this repository, get a pre-trained ELECTRA model downloading the release ELECTRA weights from the link above and unziping them under `$DATA_DIR/Electra_analysis/electra/models/electra_large/`

## Fine-tuning
Use `run_finetuning.py` to fine-tune and evaluate an ELECTRA model on a downstream NLP task. It expects three arguments:

* `--data-dir`: a directory where data, model weights, etc. are stored. By default, the script loads finetuning data from `<data-dir>/finetuning_data/<task-name>` and a vocabulary from `<data-dir>/vocab.txt`.
*  `--model-name`: a name of the pre-trained model: the pre-trained weights should exist in `data-dir/models/model-name`.
* `--hparams`: a JSON dict containing model hyperparameters, data paths, etc. (e.g., `--hparams '{"task_names": ["rte"], "model_size": "base", "learning_rate": 1e-4, ...}'`). See `configure_pretraining.py` for the supported hyperparameters.  Instead of a dict, this can also be a path to a `.json` file containing the hyperparameters. You must specify the `"task_names"` and `"model_size"` (see examples below).

To customize the training, add `--hparams '{"hparam1": value1, "hparam2": value2, ...}'` to the run command. Some particularly useful options:

* `"debug": true` fine-tunes a tiny ELECTRA model for a few steps.
* `"task_names": ["task_name"]`: specifies the tasks to train on. A list because the codebase nominally supports multi-task learning, (although be warned this has not been thoroughly tested).
* `"model_size": one of "small", "base", or "large"`: determines the size of the model; you must set this to the same size as the pre-trained model.
* `"do_train" and "do_eval"`: train and/or evaluate a model (both are set to true by default). For using `"do_eval": true` with `"do_train": false`, you need to specify the `init_checkpoint`, e.g., `python3 run_finetuning.py --data-dir $DATA_DIR --model-name electra_base --hparams '{"model_size": "base", "task_names": ["mnli"], "do_train": false, "do_eval": true, "init_checkpoint": "<data-dir>/models/electra_base/finetuning_models/mnli_model_1"}'`
* `"num_trials": n`: If >1, does multiple fine-tuning/evaluation runs with different random seeds.
* `"learning_rate": lr, "train_batch_size": n`, etc. can be used to change training hyperparameters.
* `"model_hparam_overrides": {"hidden_size": n, "num_hidden_layers": m}`, etc. can be used to changed the hyperparameters for the underlying transformer (the `"model_size"` flag sets the default values).

### Finetune ELECTRA on question answering
* **Squad 2.0**: Move downloaded datasets under `$DATA_DIR/finetuning_data/squad/(train|dev).json`
* **NewsQA transformed**: make sure to change the names of the transformed datasets to train.json|dev.json and move them `$DATA_DIR/finetuning_data/squad/(train|dev).json`
* **QUaC transformed**: make sure to change the names of the transformed datasets to train.json|dev.json and move them `$DATA_DIR/finetuning_data/squad/(train|dev).json`  
  

For the NewsQA MRQA variant it is necessary to change the task name in the `scripts/train.sh` from `["squad"]` to `["newsqa"]`


* **NewsQA MRQA variant**: Move downloaded datasets under`$DATA_DIR/finetuning_data/newsqa/(train|dev).jsonl`.

Then just execute the script.
```
cd Electra_analysis/electra/scripts
sh train.sh
```
Eval metrics will be saved in `$DATA_DIR/electra_large/results` and model weights will be saved in `$DATA_DIR/electra_large/finetuning_models` by default. Evaluation is done on the dev set by default.
